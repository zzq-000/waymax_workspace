{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.data import TFRecordDataset, AUTOTUNE\n",
    "# import tf.data.TFRecordDataset\n",
    "import jax\n",
    "from typing import Optional\n",
    "from waymax.config import DatasetConfig, DataFormat\n",
    "import jax.numpy as jnp\n",
    "import functools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./uncompressed_tf_example_training_training_tfexample.tfrecord-00000-of-01000\"\n",
    "myconfig = DatasetConfig(\n",
    "    path = \"./uncompressed_tf_example_training_training_tfexample.tfrecord-00000-of-01000\",\n",
    "    max_num_rg_points=20000,\n",
    "    data_format=DataFormat.TFRECORD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from waymax.dataloader import womd_utils\n",
    "def preprocess_serialized_womd_data(\n",
    "    serialized: bytes, config: DatasetConfig\n",
    ") -> dict[str, tf.Tensor]:\n",
    "  \"\"\"Parses serialized tf example into tf Tensor dict.\"\"\"\n",
    "  womd_features = womd_utils.get_features_description(\n",
    "      include_sdc_paths=config.include_sdc_paths,\n",
    "      max_num_rg_points=config.max_num_rg_points,\n",
    "      num_paths=config.num_paths,\n",
    "      num_points_per_path=config.num_points_per_path,\n",
    "  )\n",
    "\n",
    "  deserialized = tf.io.parse_example(serialized, womd_features)\n",
    "  return preprocess_womd_example(\n",
    "      deserialized,\n",
    "      aggregate_timesteps=config.aggregate_timesteps,\n",
    "      max_num_objects=config.max_num_objects,\n",
    "  )\n",
    "\n",
    "\n",
    "def preprocess_womd_example(\n",
    "    example: dict[str, tf.Tensor],\n",
    "    aggregate_timesteps: bool,\n",
    "    max_num_objects: Optional[int] = None,\n",
    ") -> dict[str, tf.Tensor]:\n",
    "  \"\"\"Preprocesses dict of tf tensors, keyed by str.\"\"\"\n",
    "\n",
    "  if aggregate_timesteps:\n",
    "    processed = womd_utils.aggregate_time_tensors(example)\n",
    "    wrap_yaws = lambda yaws: (yaws + jnp.pi) % (2 * jnp.pi) - jnp.pi\n",
    "    processed['state/all/bbox_yaw'] = wrap_yaws(processed['state/all/bbox_yaw'])\n",
    "  else:\n",
    "    processed = example\n",
    "\n",
    "  if max_num_objects is not None:\n",
    "    # TODO check sdc included if it is needed.\n",
    "    return {\n",
    "        k: v[:max_num_objects] if k.startswith('state/') else v\n",
    "        for k, v in processed.items()\n",
    "    }\n",
    "  else:\n",
    "    return processed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_load = [path]\n",
    "files = tf.data.Dataset.from_tensor_slices(files_to_load)\n",
    "\n",
    "files = files.shard(jax.process_count(), jax.process_index())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = files.interleave(tf.data.TFRecordDataset, num_parallel_calls=tf.data.AUTOTUNE, deterministic=True)\n",
    "# data = tf.data.TFRecordDataset(files)\n",
    "# myconfig.aggregate_timesteps = False\n",
    "preprocess_fn = functools.partial(preprocess_serialized_womd_data, config = myconfig)\n",
    "\n",
    "\n",
    "data = data.map(\n",
    "    preprocess_fn, num_parallel_calls=AUTOTUNE, deterministic=True\n",
    ")\n",
    "\n",
    "# print(type(data))\n",
    "# print(type(data.take(1)))\n",
    "# for item in data.take(1):\n",
    "#     print(len(item.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "from waymax.dataloader import womd_factories\n",
    "\n",
    "print(\"hello\")\n",
    "for item in data.take(1):\n",
    "    # for k in item:\n",
    "    #     print(k, item[k].shape)\n",
    "    s = womd_factories.simulator_state_from_womd_dict(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 20000 None None\n",
      "True None\n"
     ]
    }
   ],
   "source": [
    "print(myconfig.include_sdc_paths, myconfig.max_num_rg_points, myconfig.num_paths,myconfig.num_points_per_path)\n",
    "\n",
    "print(myconfig.aggregate_timesteps, myconfig.max_num_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waymax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
